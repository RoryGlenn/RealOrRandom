{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IDo6Mz1MoJxR"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "Turn in the assignment via Canvas.\n",
        "\n",
        "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel→→Restart) and then run all cells (in the menubar, select Cell→→Run All).\n",
        "\n",
        "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nOfazHDtoJxS"
      },
      "outputs": [],
      "source": [
        "NAME = \"Rory Glenn\"\n",
        "STUDENT_ID = \"1713714\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DnqS9q_LoJxW"
      },
      "source": [
        "## Problem 1 -  Bayes' Theorem\n",
        "\n",
        "Suppose there exists a test to classify emails as spam or not spam based on the contained words. This test accurately identifies spam (if it is actually spam) 95% of the time. The prevalence of spam emails is 3 in 10. Also, if an email isn't spam, the test will incorrectly classify it as spam 5% of the time.\n",
        "\n",
        "NOTE: For each of the following questions, please give each answer to at least 2 significant digit accuracy. To accomplish this, don't round off your results until the very last step of each calculation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iScoUr4VoJxW"
      },
      "source": [
        "### a. What's the probability that an email picked at random is spam? What's the probability that an email picked at random isn't spam?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tD5BY6oBoJxX"
      },
      "source": [
        "The probability that an email picked at random is spam is 0.30\n",
        "The probability that an email picked at random isn't spam is 0.70\n",
        "\n",
        "$P(Spam) = 0.30$\n",
        "\n",
        "\n",
        "$P(not Spam) = 0.70$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6V9jAYoNoJxX"
      },
      "source": [
        "### b. If you test an email and it reports positive for spam, what is the probability that it is spam?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "20zMUeQdoJxY"
      },
      "source": [
        "<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\dpi{150}&space;\\bg_white&space;\\large&space;P(positive&space;|&space;spam)&space;=&space;(&space;P(spam)*P(positive|spam)&space;)&space;/&space;(P(spam)*P(positive&space;|&space;spam)&space;&plus;&space;P(not&space;spam)&space;*&space;P(positive&space;|&space;not&space;spam))\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\dpi{150}&space;\\bg_white&space;\\large&space;P(positive&space;|&space;spam)&space;=&space;(&space;P(spam)*P(positive|spam)&space;)&space;/&space;(P(spam)*P(positive&space;|&space;spam)&space;&plus;&space;P(not&space;spam)&space;*&space;P(positive&space;|&space;not&space;spam))\" title=\"\\large P(positive | spam) = ( P(spam)*P(positive|spam) ) / (P(spam)*P(positive | spam) + P(not spam) * P(positive | not spam))\" /></a>\n",
        "\n",
        "<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\dpi{150}&space;\\bg_white&space;\\large&space;P(positive|spam)&space;=&space;0.8906\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\dpi{150}&space;\\bg_white&space;\\large&space;P(positive|spam)&space;=&space;0.8906\" title=\"\\large P(positive|spam) = 0.8906\" /></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n4ALhwnmoJxY"
      },
      "source": [
        "### c. If you test an email and it reports negative for spam, what is the probability that it is spam?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RqAiQbSLoJxZ"
      },
      "source": [
        "<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\inline&space;\\dpi{150}&space;\\bg_white&space;\\LARGE&space;P(spam|negative)&space;=&space;P(spam)*P(negative|spam)&space;/&space;P(spam)P(negative|spam)&space;&plus;&space;P(not&space;spam)*P(negative|not&space;spam)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\inline&space;\\dpi{150}&space;\\bg_white&space;\\LARGE&space;P(spam|negative)&space;=&space;P(spam)*P(negative|spam)&space;/&space;P(spam)P(negative|spam)&space;&plus;&space;P(not&space;spam)*P(negative|not&space;spam)\" title=\"\\LARGE P(spam|negative) = P(spam)*P(negative|spam) / P(spam)P(negative|spam) + P(not spam)*P(negative|not spam)\" /></a>\n",
        "\n",
        "<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\inline&space;\\dpi{150}&space;\\bg_white&space;\\LARGE&space;P(spam|negative)&space;=&space;0.0220\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\inline&space;\\dpi{150}&space;\\bg_white&space;\\LARGE&space;P(spam|negative)&space;=&space;0.0220\" title=\"\\LARGE P(spam|negative) = 0.0220\" /></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FrJ1hKatYaiU"
      },
      "source": [
        "## Monte Carlo Simulations\n",
        "\n",
        "Monte Carlo simulations can yield numeric solutions to probability problems that aren't possible to solve analytically. These simulations are also often easy to code up, and so also provide a way to check one's calculations for problems that amenable to analysis. So this is an important technique to become familiar with.\n",
        "\n",
        "Basically, one creates a simulation of the situation, and runs many trials that allow one to estimate the probabilities by computing proportions. \n",
        "\n",
        "First we give you an example of a Monte Carlo simulation, and then you'll solve such a problem yourself.\n",
        "\n",
        "### Example\n",
        "\n",
        "If you toss a coin 10 times, with what probability are you likely to see the subsequence {H, H, T, T} appear?\n",
        "\n",
        "Be patient, this may take a bit to run, but notice how straightforward the coding is. The simplicity of the Monte Carlo method makes it very powerful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vBn1ndB3oJxa"
      },
      "outputs": [],
      "source": [
        "from numpy.random import randint\n",
        "import numpy as np\n",
        "\n",
        "num_tosses = 10    # tosses per trial\n",
        "num_trials = 100000\n",
        "\n",
        "# This sets the feedback interval so we know the program hasn't crashed.\n",
        "feedback = int(np.round(num_trials / 10))\n",
        "\n",
        "num_seq_found = 0   # to count the number of target subsequences detected\n",
        "for t in range(1, num_trials + 1):\n",
        "    \n",
        "    # To see the progress.\n",
        "    if t % feedback == 0:  \n",
        "        print(np.round(100 * t / num_trials, 1), '%  complete:   prob =', num_seq_found / t)\n",
        "        \n",
        "    # Roll the die num_tosses times.\n",
        "    trial = [randint(1, 3) for _ in range(num_tosses)]\n",
        "    # Find the indices of all the 2s.\n",
        "    heads = [i for i in range(num_tosses) if trial[i] == 1]\n",
        "    \n",
        "    # Search to see if after each 2 we have a 4 followed by a 6.\n",
        "    for j in heads:\n",
        "        if j < num_tosses - 3 and trial[j] == 1 and trial[j + 1] == 1 and trial[j + 2] == 2 and trial[j + 3] == 2:\n",
        "            # We've found the target subsequence.\n",
        "            num_seq_found += 1\n",
        "    \n",
        "print('Probability of this subsequence =', num_seq_found / num_trials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IT-eRCtiYaib"
      },
      "source": [
        "## Problem 2  -  Monte Carlo Simulation\n",
        "\n",
        "Consider two dice: One fair and one unfair. The unfair die has a 50% chance to land on the 6 face, and even chance for the rest of the faces.\n",
        "\n",
        "Write code that rolls both dice and computes the sum.\n",
        "\n",
        "Do this many times, and give the mean of all the sums.  This will converge to the expected average sum of both randomly rolled dice. You may need to run this several times to be sure of your accuracy. You can check the correctness of your Monte Carlo Simulation by solving this problem analytically.\n",
        "\n",
        "Hint:\n",
        "\n",
        "https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.choice.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "H4GVkg25oJxd",
        "outputId": "6622f1b1-68ef-43bf-bbd9-3a1c73171914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.0 % complete:   mean_sum = 7.501410141014094\n",
            "20.0 % complete:   mean_sum = 7.505585279263957\n",
            "30.0 % complete:   mean_sum = 7.499466648888293\n",
            "40.0 % complete:   mean_sum = 7.498762469061693\n",
            "50.0 % complete:   mean_sum = 7.497725954519137\n",
            "60.0 % complete:   mean_sum = 7.4991316521942695\n",
            "70.0 % complete:   mean_sum = 7.499574279632624\n",
            "80.0 % complete:   mean_sum = 7.498918736484258\n",
            "90.0 % complete:   mean_sum = 7.4967944088267995\n",
            "100.0 % complete:   mean_sum = 7.496948969489709\n",
            "mean sum = 7.496946000000014\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.random import choice\n",
        "\n",
        "num_tosses = 10\n",
        "num_trials = 100000\n",
        "die_number = [1, 2, 3, 4, 5, 6]\n",
        "average_list = []\n",
        "mean_sum = 0\n",
        "feedback = int(np.round(num_trials / 10))\n",
        "\n",
        "for t in range(1, num_trials + 1):\n",
        "\n",
        "    if t % feedback == 0:\n",
        "        average_total = 0\n",
        "        for k in range(len(average_list)):\n",
        "            average_total += average_list[k]                # add up all the averages\n",
        "\n",
        "        average_total = average_total / len(average_list)   # get the average of all the averages\n",
        "        print(np.round(100 * t / num_trials, 1), \"% complete:   mean_sum =\", average_total)  # output the average of all averages\n",
        "\n",
        "    fair_die_trial = [np.random.randint(1, 6) for _ in range(num_tosses)]\n",
        "    unfair_die_trial = [int(np.random.choice(die_number, 1, p=[0.1, 0.1, 0.1, 0.1, 0.1, 0.5])) for _ in range(num_tosses)]\n",
        "\n",
        "    sum = []\n",
        "    for i in range(num_tosses):\n",
        "        sum.append(fair_die_trial[i] + unfair_die_trial[i])     # sum the die rolls\n",
        "\n",
        "    trial_average = 0\n",
        "    for j in range(num_tosses):\n",
        "        trial_average += sum[j]         # add up all the sums\n",
        "    trial_average /= len(sum)           # take the average of the sums\n",
        "    average_list.append(trial_average)  # append the average of the sums to list\n",
        "\n",
        "for i in range(0, len(average_list)):\n",
        "    mean_sum += average_list[i]         # sum over all the averages\n",
        "\n",
        "mean_sum = mean_sum / len(average_list) # take the average of all numbers\n",
        "print('mean sum =', mean_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JqLfHsyWoJxg"
      },
      "source": [
        "#### [YOUR ANSWER HERE] ###\n",
        "\n",
        "mean sum = 7.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YVsAdkmbD-Sy"
      },
      "source": [
        "\n",
        "## Problem 3 - Data Processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "esDKYNhE_7cP"
      },
      "source": [
        "There are three types of data:\n",
        "\n",
        "1.   **Numerical**: For example height, price of a good, heart rate and so on. These data are quantitative in nature.\n",
        "2.   **Categorical**: While these are qualitative in nature. For example \"Yes\" or \"No\", \"Red\",\"Green\" or \"Blue\" and \"Doggo\" or \"Kitty\".\n",
        "3.   **Ordinal**: This is a combination of the above, for example movie ratings of 1-5.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dfzrHV3fFAv1"
      },
      "source": [
        "Machine learning algorithms need data to work. Before you start applying machine learning, you must process your data into a form a machine learning model will expect. This is known as **data preprocessing**.  \n",
        "\n",
        "The data we are working with pertains to the airline domain in India. It was used in a hackathon, where the goal was to predict airline prices given a set of *features*. First let's download a dataset, go to link http://download853.mediafire.com/orceo1u9llng/l7j86drkdln9aye/Data_Train.xlsx and download the Data_Train.xlsx. Then upload the file to your notebook (without renaming) by clicking on the File icon on the left side and then clicking \"Upload\" and upload the \"Data_Train.xlsx\" file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tl-cv1UmgLEk"
      },
      "source": [
        "Now that we have some data, we need the appropriate libraries to first read the data in and if need be manipulate the data for use in machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mxUdD1br_7-b"
      },
      "outputs": [],
      "source": [
        "# We import pandas, a Python library that allows us to read in common data formats such as .csv, .xlsx, etc... \n",
        "# as a dataframe, essentially a matrix of features.\n",
        "import pandas as pd\n",
        "data = pd.read_excel('Data_Train.xlsx')  # Read in the data we downloaded\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "colab_type": "code",
        "id": "kCfYBVElWpLF",
        "outputId": "119fd0e0-ab15-4e83-d95f-772c06f452b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Airline</th>\n",
              "      <th>Date_of_Journey</th>\n",
              "      <th>Source</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Route</th>\n",
              "      <th>Dep_Time</th>\n",
              "      <th>Arrival_Time</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Total_Stops</th>\n",
              "      <th>Additional_Info</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>24/03/2019</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>New Delhi</td>\n",
              "      <td>BLR → DEL</td>\n",
              "      <td>22:20</td>\n",
              "      <td>01:10 22 Mar</td>\n",
              "      <td>2h 50m</td>\n",
              "      <td>non-stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>3897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Air India</td>\n",
              "      <td>1/05/2019</td>\n",
              "      <td>Kolkata</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>CCU → IXR → BBI → BLR</td>\n",
              "      <td>05:50</td>\n",
              "      <td>13:15</td>\n",
              "      <td>7h 25m</td>\n",
              "      <td>2 stops</td>\n",
              "      <td>No info</td>\n",
              "      <td>7662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jet Airways</td>\n",
              "      <td>9/06/2019</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Cochin</td>\n",
              "      <td>DEL → LKO → BOM → COK</td>\n",
              "      <td>09:25</td>\n",
              "      <td>04:25 10 Jun</td>\n",
              "      <td>19h</td>\n",
              "      <td>2 stops</td>\n",
              "      <td>No info</td>\n",
              "      <td>13882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>12/05/2019</td>\n",
              "      <td>Kolkata</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>CCU → NAG → BLR</td>\n",
              "      <td>18:05</td>\n",
              "      <td>23:30</td>\n",
              "      <td>5h 25m</td>\n",
              "      <td>1 stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>6218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IndiGo</td>\n",
              "      <td>01/03/2019</td>\n",
              "      <td>Banglore</td>\n",
              "      <td>New Delhi</td>\n",
              "      <td>BLR → NAG → DEL</td>\n",
              "      <td>16:50</td>\n",
              "      <td>21:35</td>\n",
              "      <td>4h 45m</td>\n",
              "      <td>1 stop</td>\n",
              "      <td>No info</td>\n",
              "      <td>13302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Airline Date_of_Journey    Source  ... Total_Stops Additional_Info  Price\n",
              "0       IndiGo      24/03/2019  Banglore  ...    non-stop         No info   3897\n",
              "1    Air India       1/05/2019   Kolkata  ...     2 stops         No info   7662\n",
              "2  Jet Airways       9/06/2019     Delhi  ...     2 stops         No info  13882\n",
              "3       IndiGo      12/05/2019   Kolkata  ...      1 stop         No info   6218\n",
              "4       IndiGo      01/03/2019  Banglore  ...      1 stop         No info  13302\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can examine the data by looking at the first 5 entries using the head() function.\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nf1cdIceaQOb"
      },
      "source": [
        "### Exploratory Data Analysis\n",
        "\n",
        "Before we start processing we should examine our data. This is known as exploratory data analysis.\n",
        "\n",
        "Use seaborn to carry out data exploratory analysis to observe the distribution of Airlines.\n",
        "\n",
        "[HINT: Use sns.countplot()]\n",
        "\n",
        "Comment on the distribution of Airlines and what this could mean for price prediction?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "anf-MLajPtd0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IMtdMgMAJlM8"
      },
      "source": [
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "colab_type": "code",
        "id": "KvPpYDYtaPoH",
        "outputId": "96f33eae-ef92-4df6-abd0-b4f89970f7fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
              " <a list of 12 Text major ticklabel objects>)"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Used for plotting\n",
        "\n",
        "sns.countplot(\"Airline\", data=data)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Comment on the distribution of Airlines and \n",
        "# what this could mean for price prediction?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "reNlqIhglCG-"
      },
      "source": [
        "### Data Preprocessing and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4AjtkWP-iD8u"
      },
      "source": [
        "We observe that this dataset has a mixture of data types ranging from: strings, date-time strings, and integers. \n",
        "\n",
        "Now we are ready to do some data preprocessing! Let's pretend we want to predict \"Price\", then it is reasonable to assume  \"Airline\", \"Date_of_Journey\", \"Source\", \"Destination\" , and \"Route\" could be useful features. We ignore \"Dep_Time\", \"Arrival_Time\" and \"Duration\". Similarly \"Total_Stops\" can be inferred from \"Route\" and \"Additional_Info\" could be useful in the future but for now we ignore it.\n",
        "\n",
        "The goal of preprocessing is to handle any irregularities in the dataset such as missing values, awkwardly formatted entries and any other outlier cases (also known as data cleaning).\n",
        "An example of a case we would need to deal with is in \"Arrival_Time\" row 1, the time and date is specified while other rows only have the time. A decision would have to be made whether or not to keep the date or just use the time. \n",
        "\n",
        "After our data is cleaned, we can confidently transform our data into the form machine learning models expect. Machine learning models are mathematical models and they work with vectors and matricies. Therefore after we finishing preprocessing we should have a dataframe of numbers i.e a matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JdjiA8A4k98c"
      },
      "source": [
        "#### a) Processing: \"Airline\", \"Source\" and \"Destination\"\n",
        "\n",
        "The data in these columns are strings and therefore not numerical. They must be transformed. There are several ways to do this transformation, but you can try the most simple method for this assignment. \n",
        "\n",
        "Given these columns transform the entries from strings to numerical data by:\n",
        "\n",
        "i) First for **each** column define a **vocabulary**, that is a collection of all the unique words. \n",
        "\n",
        "ii) Second, with the knowledge of each unique word create mapping of each word to a unique integer.\n",
        "\n",
        "iii) Third, with your mapping apply it to each column to complete the transformation to a numerical representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FhPLT9ocX79U"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Step 1: Create a vocabulary for each column\n",
        "# Step 2: Create a mapping function from each word in the vocabulary to a unique integer\n",
        "# Step 3: Replce all words in the original data with the assigned integers\n",
        "\n",
        "def add_items(my_set, my_dict, my_string):\n",
        "  count = 1\n",
        "  for name in data[my_string]:\n",
        "    my_set.add(name)\n",
        "  for item in my_set:\n",
        "    my_dict[item] = count\n",
        "    count += 1\n",
        "  return my_set, my_dict\n",
        "\n",
        "def replace_items(my_data, my_dict, my_string):\n",
        "  my_data = my_data.replace({my_string: my_dict})\n",
        "  return my_data\n",
        "\n",
        "set_airlines = set()\n",
        "set_source = set()\n",
        "set_destination = set()\n",
        "dict_airlines = {}\n",
        "dict_source = {}\n",
        "dict_destination = {}\n",
        "\n",
        "set_airlines, dict_airlines = add_items(set_airlines, dict_airlines, \"Airline\")\n",
        "set_source, dict_source = add_items(set_source, dict_source, \"Source\")\n",
        "set_destination, dict_destination = add_items(set_destination, dict_destination, \"Destination\")\n",
        "\n",
        "data = replace_items(data, dict_airlines, \"Airline\")\n",
        "data = replace_items(data, dict_source, \"Source\")\n",
        "data = replace_items(data, dict_destination, \"Destination\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2zXHg1stAiMF"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mc9twBzYpP3o"
      },
      "source": [
        "#### b) Processing: \"Date_of_Journey\"\n",
        "\n",
        "i) The entries in this column cannot be understood by any machine learning model as is. We must transform them to numerical representation.\n",
        "\n",
        "Using pandas separate the dates into separate \"Months\" and \"Weekdays\". \n",
        "\n",
        "See example of creating a new column below.\n",
        "\n",
        "HINT: dt.day_name() gets the weekday from a datatime format\n",
        "and dt.month_name() gets the month name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1Vk2WQcyst4q"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "# According to TA Jose Sepulveda, import date as dt is not needed because\n",
        "# dt is already a member variable in the Dataframe class "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MyH1EyaksJBH"
      },
      "outputs": [],
      "source": [
        "# Overwrite column to be in datatime format\n",
        "# That is: YYYY/MM/DD -> YYYY-MM-DD\n",
        "data['Date_of_Journey'] = pd.to_datetime(data['Date_of_Journey'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Bboi8CHCschm"
      },
      "outputs": [],
      "source": [
        "data['day_of_week'] = data[\"Date_of_Journey\"].dt.day_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9a4dw9JFseNo"
      },
      "outputs": [],
      "source": [
        "data['Journey_Month'] = data[\"Date_of_Journey\"].dt.month_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RmS5WS_ktK3F"
      },
      "source": [
        "ii) Now that you have these new columns, are these features ready for a machine learning model? Please explain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iH2zkCjLJrYD"
      },
      "source": [
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qyKIJfuVt7Yf"
      },
      "source": [
        "#### c) Processing: Route\n",
        "\n",
        "Processing \"Route\" is tricky as they are all different lengthed strings. Why is this a problem? It doesn't have to be if we feed our algorithm an entry one by one but that can be slow. We want to utilize the fact computers are designed to do matrix operations quickly.\n",
        "\n",
        "To preprocess the \"Route\" column do the following:\n",
        "\n",
        "i) Separate the strings by the empty string using split().\n",
        "\n",
        "ii) Determine a vocabulary made up of each unique airport code and you may include the arrow that separates the codes.\n",
        "\n",
        "iii) Using this vocabulary information devise a way to make sure all the strings/features are the same size and **NO NEED TO IMPLEMENT** it. Discuss why you choose that method and any limitations you can think of. [HINT: Think about the vocabulary approach from above and an approach called one hot encoding.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j4DyhPNjvg9p"
      },
      "outputs": [],
      "source": [
        "data['Route'].str.split()\n",
        "routes = data['Route'].unique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dPE54VQSSTT"
      },
      "source": [
        "In order to implement this vocabulary information, I would either use one hot encoding or multi hot encoding.\n",
        "Some of the problems with one hot encoding include problems with the states. It also seems to be very computational expensive given a large enough data set. I think that it would also be difficult for us to recognize the data with the human eye but for a computer it is fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "URdm0uwHySZH"
      },
      "source": [
        "#### d) Feature Engineering\n",
        "Surprise surprise! We have been doing feature engineering all along by preprocessing the data and trasnforming or engineering it into a form a machine learning algorithm will expect.\n",
        "\n",
        "But this doesn't mean the features cannot be improved!\n",
        "\n",
        "Consider the \"Airline\" column from part a) each airline is mapped to a unique integer. Imagine a scenario where we have hundreds of unique airlines, the airline mapped to 100 for example would be weighted more than the airline mapped to 1. Similarly for columns \"Source\" and \"Destination\". To fix this discrepancy, we utilize standardization or normalization.\n",
        "\n",
        "Use standarization to map all the values in these columns to the range [0,1] by using the following expression: \n",
        "\n",
        "```scaled_value = (value - min) / (max - min)```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "MpPYzrrF0Pyt",
        "outputId": "6402c469-d7bb-468c-bd94-db51c393960b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15, 48, 47, 28, 28, 42, 49, 12, 12, 45, 26, 1, 34, 11, 44, 16, 20, 33, 11, 5, 29, 10, 49, 14, 29, 4, 11, 43, 33, 9, 43, 44, 2, 44, 43, 34, 13, 3, 25, 36, 36, 45, 24, 12, 2, 3, 22, 8, 40, 5, 39, 49, 44, 13, 3, 47, 41, 37, 3, 26, 11, 50, 22, 11, 25, 20, 16, 18, 32, 45, 38, 37, 29, 7, 8, 1, 27, 19, 1, 33, 37, 1, 49, 2, 47, 26, 21, 50, 30, 20, 22, 42, 7, 41, 49, 37, 35, 11, 12, 3]\n",
            "[0.2857142857142857, 0.9591836734693877, 0.9387755102040817, 0.5510204081632653, 0.5510204081632653, 0.8367346938775511, 0.9795918367346939, 0.22448979591836735, 0.22448979591836735, 0.8979591836734694, 0.5102040816326531, 0.0, 0.673469387755102, 0.20408163265306123, 0.8775510204081632, 0.30612244897959184, 0.3877551020408163, 0.6530612244897959, 0.20408163265306123, 0.08163265306122448, 0.5714285714285714, 0.1836734693877551, 0.9795918367346939, 0.2653061224489796, 0.5714285714285714, 0.061224489795918366, 0.20408163265306123, 0.8571428571428571, 0.6530612244897959, 0.16326530612244897, 0.8571428571428571, 0.8775510204081632, 0.02040816326530612, 0.8775510204081632, 0.8571428571428571, 0.673469387755102, 0.24489795918367346, 0.04081632653061224, 0.4897959183673469, 0.7142857142857143, 0.7142857142857143, 0.8979591836734694, 0.46938775510204084, 0.22448979591836735, 0.02040816326530612, 0.04081632653061224, 0.42857142857142855, 0.14285714285714285, 0.7959183673469388, 0.08163265306122448, 0.7755102040816326, 0.9795918367346939, 0.8775510204081632, 0.24489795918367346, 0.04081632653061224, 0.9387755102040817, 0.8163265306122449, 0.7346938775510204, 0.04081632653061224, 0.5102040816326531, 0.20408163265306123, 1.0, 0.42857142857142855, 0.20408163265306123, 0.4897959183673469, 0.3877551020408163, 0.30612244897959184, 0.3469387755102041, 0.6326530612244898, 0.8979591836734694, 0.7551020408163265, 0.7346938775510204, 0.5714285714285714, 0.12244897959183673, 0.14285714285714285, 0.0, 0.5306122448979592, 0.3673469387755102, 0.0, 0.6530612244897959, 0.7346938775510204, 0.0, 0.9795918367346939, 0.02040816326530612, 0.9387755102040817, 0.5102040816326531, 0.40816326530612246, 1.0, 0.5918367346938775, 0.3877551020408163, 0.42857142857142855, 0.8367346938775511, 0.12244897959183673, 0.8163265306122449, 0.9795918367346939, 0.7346938775510204, 0.6938775510204082, 0.20408163265306123, 0.22448979591836735, 0.04081632653061224]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "array = [random.randint(1,50) for i in range(0, 100)]\n",
        "print(array)\n",
        "\n",
        "print([(v - min(array)) / (max(array) - min(array)) for v in array])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of CSE 144 - Assignment 1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "faeaa8e0f5ecc5f61274cbfa7a2c54062e92cea1bf43625e2209112a5d106fa3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
